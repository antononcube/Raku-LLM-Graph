{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee4231a",
   "metadata": {},
   "source": [
    "# Summarize large text\n",
    "\n",
    "<p style=\"font-size: 20px; font-weight: bold; font-style: italic;\">...via LLM-graph</p>\n",
    "\n",
    "Anton Antonov   \n",
    "August, September 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3db3414",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04667c07",
   "metadata": {},
   "source": [
    "This notebook illustrates how to specify a Large Language Model (LLM) graph for deriving comprehensive summaries of large texts. \n",
    "The LLM graph is based on different LLM- and non-LLM functions .\n",
    "The Raku package [\"LLM::Graph\"](https://raku.land/zef:antononcube/LLM::Graph) is used, [AAp1].\n",
    "\n",
    "Using the LLM graph is an alternative to the Literate programming based solutions shown in [AA1, AAn1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2920a3",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b633650",
   "metadata": {},
   "outputs": [],
   "source": [
    "use LLM::Graph;\n",
    "use Data::Importers;\n",
    "\n",
    "use LLM::Tooling;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9376263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sink my $conf5-mini = llm-configuration('ChatGPT', model => 'gpt-5-mini');\n",
    "sink my $conf5 = llm-configuration('ChatGPT', model => 'gpt-5');\n",
    "sink my $conf41-mini = llm-configuration('ChatGPT', model => 'gpt-4.1-mini', temperature => 0.55, max-tokens => 4096);\n",
    "sink my $conf41 = llm-configuration('ChatGPT', model => 'gpt-4.1', temperature => 0.45, max-tokens => 8192);\n",
    "sink my $conf4o-mini = llm-configuration('ChatGPT', model => 'gpt-4o-mini', temperature => 0.45, max-tokens => 8192);\n",
    "sink my $conf4o = llm-configuration('ChatGPT', model => 'gpt-4o', temperature => 0.45, max-tokens => 8192);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a262388",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## LLM graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce318eca",
   "metadata": {},
   "source": [
    "Specify the LLM graph nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a85f40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sink my %rules =\n",
    "TypeOfInput => sub ($_) {\n",
    "        \"Determine the input type of\\n\\n$_.\\n\\nThe result should be one of: 'Text', 'URL', 'FilePath', or 'Other'.\"  ~ \n",
    "        llm-prompt('NothingElse')('single string')\n",
    "    },\n",
    "\n",
    "IngestText =>  { eval-function => sub ($TypeOfInput, $_) { $TypeOfInput ~~ / URL | FilePath/ ?? data-import($_) !! $_} },\n",
    "\n",
    "Title => { \n",
    "    eval-function => sub ($IngestText, $with-title = Whatever) { $with-title ~~ Str:D ?? $with-title !! llm-synthesize([llm-prompt(\"TitleSuggest\")($IngestText, 'article'), \"Short title with less that 6 words\"]) },\n",
    "},\n",
    "\n",
    "Summary => sub ($IngestText) { llm-prompt(\"Summarize\")() ~ \"\\n\\n$IngestText\" },\n",
    "\n",
    "TopicsTable => sub ($IngestText) { llm-prompt(\"ThemeTableJSON\")($IngestText, 'article', 20) },\n",
    "\n",
    "ThinkingHats => sub ($IngestText) { llm-prompt(\"ThinkingHatsFeedback\")($IngestText, <yellow grey>, format => 'HTML') },\n",
    "\n",
    "MindMap => sub ($IngestText) { llm-prompt('MermaidDiagram')($IngestText) },\n",
    "\n",
    "Report => { eval-function => \n",
    "    sub ($Title, $Summary, $TopicsTable, $MindMap, $ThinkingHats) { \n",
    "        [\n",
    "            \"# $Title\",\n",
    "            '### *LLM summary report*',\n",
    "            '## Summary',\n",
    "            $Summary,\n",
    "            '## Topics',\n",
    "            to-html(\n",
    "                from-json($TopicsTable.subst(/ ^ '```json' | '```' $/):g),\n",
    "                field-names => <theme content>,\n",
    "                align => 'left'),\n",
    "            \"## Mind map\",\n",
    "            $MindMap,\n",
    "            '## Thinking hats',\n",
    "            $ThinkingHats.subst(/ ^ '```html' | '```' $/):g\n",
    "        ].join(\"\\n\\n\")\n",
    "    } \n",
    "},\n",
    "\n",
    "ExportAndOpen => {\n",
    "    eval-function => sub ($Report) {\n",
    "       spurt('./Report.md', $Report);\n",
    "       shell \"open ./Report.md\" \n",
    "    },\n",
    "    test-function => -> $export-and-open = True { $export-and-open ~~ Bool:D && $export-and-open || $export-and-open.Str.lc ∈ <true yes open> }\n",
    "}\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea19308",
   "metadata": {},
   "source": [
    "Make the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915edfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM::Graph(size => 9, nodes => ExportAndOpen, IngestText, MindMap, Report, Summary, ThinkingHats, Title, TopicsTable, TypeOfInput)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $gCombinedSummary = llm-graph(%rules, llm-evaluator => $conf41-mini, :async, :progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f8293",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Full computation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79931a",
   "metadata": {},
   "source": [
    "URL and text statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c29e8b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(chars => 5957 words => 1132 lines => 157)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my $url = 'https://raw.githubusercontent.com/antononcube/RakuForPrediction-blog/refs/heads/main/Data/Graph-neat-examples-in-Raku-Set-2-YouTube.txt';\n",
    "my $txtFocus = data-import($url);\n",
    "\n",
    "text-stats($txtFocus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389c38a4",
   "metadata": {},
   "source": [
    "Computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64399560",
   "metadata": {},
   "outputs": [],
   "source": [
    "$gCombinedSummary.eval({'$_' => $url, with-title => '«Graph» neat examples, set 3'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3866e378",
   "metadata": {},
   "source": [
    "**Remark:** Instead of deriving the title using an LLM, the title is specified as an argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f650a6c",
   "metadata": {},
   "source": [
    "Show the corresponding graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#% html\n",
    "$gCombinedSummary.dot(node-width => 1.2, theme => 'ortho'):svg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0ed00",
   "metadata": {},
   "source": [
    "Final result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#% markdown\n",
    "$gCombinedSummary.nodes<Report><result>.subst(/'```html' | '```' $/):g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a99c7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Partial evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd5b4a",
   "metadata": {},
   "source": [
    "Drop the results in `LLM::Graph` computed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a78d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM::Graph(size => 9, nodes => ExportAndOpen, IngestText, MindMap, Report, Summary, ThinkingHats, Title, TopicsTable, TypeOfInput)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "$gCombinedSummary.clear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175cf587",
   "metadata": {},
   "source": [
    "Here the are normalized nodes without results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83c399e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary => sub { }\n",
      "Title => {eval-function => sub { }}\n",
      "ThinkingHats => sub { }\n",
      "IngestText => {eval-function => sub { }}\n",
      "MindMap => sub { }\n",
      "TopicsTable => sub { }\n",
      "Report => {eval-function => sub { }}\n",
      "TypeOfInput => sub { }\n",
      "ExportAndOpen => {eval-function => sub { }, test-function => -> $export-and-open = Bool::True { #`(Block|6072790532248) ... }}\n"
     ]
    }
   ],
   "source": [
    ".say for |$gCombinedSummary.nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc7900d",
   "metadata": {},
   "source": [
    "Here all results are pre-assigned as arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd624999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLM::Graph(size => 9, nodes => ExportAndOpen, IngestText, MindMap, Report, Summary, ThinkingHats, Title, TopicsTable, TypeOfInput)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "$gCombinedSummary.eval({\n",
    "    '$_' => $url, \n",
    "    Title => '«Graph» neat examples, set 3', \n",
    "    :export-and-open,\n",
    "    TypeOfInput => 'Other',\n",
    "    Summary => 'In brief',\n",
    "    IngestText => 'Ingest text',\n",
    "    TopicsTable => '[\"TopicsTable\"]',\n",
    "    ThinkingHats => 'Thinking hats',\n",
    "    MindMap => 'Mind-map graph'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825d443f",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836740f7",
   "metadata": {},
   "source": [
    "### Blog posts\n",
    "\n",
    "[AA1] Anton Antonov,\n",
    "[\"Parameterized Literate Programming\"](https://rakuforprediction.wordpress.com/2025/06/21/parameterized-literate-programming/),\n",
    "(2025),\n",
    "[RakuForPrediction at WordPress](https://rakuforprediction.wordpress.com).\n",
    "\n",
    "### Notebooks\n",
    "\n",
    "[AAn1] Anton Antonov,\n",
    "[\"LLM comprehensive summary template for large texts\"](https://community.wolfram.com/groups/-/m/t/3448842),\n",
    "(2025),\n",
    "[Wolfram Community](https://community.wolfram.com).\n",
    "\n",
    "### Packages\n",
    "\n",
    "[AAp1] Anton Antonov, \n",
    "[LLM::Graph, Raku package](https://github.com/antononcube/Raku-LLM-Graph),\n",
    "(2025),\n",
    "[GitHub/antononcube](https://github.com/antononcube)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RakuChatbook",
   "language": "raku",
   "name": "raku"
  },
  "language_info": {
   "file_extension": ".raku",
   "mimetype": "text/x-raku",
   "name": "raku",
   "version": "6.d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
